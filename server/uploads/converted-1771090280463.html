
        <!DOCTYPE html>
        <html>
        <head>
          <style>
            body { font-family: sans-serif; padding: 20px; }
            table { border-collapse: collapse; width: 100%; margin-bottom: 20px; }
            th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
            th { bg-color: #f2f2f2; }
            h2 { color: #333; border-bottom: 2px solid #eee; padding-bottom: 10px; }
          </style>
        </head>
        <body>
      <h2>DAA</h2><html><head><meta charset="utf-8"/><title>SheetJS Table Export</title></head><body><table><tr><td data-t="s" data-v="What is the definition of an algorithm?" id="sjs-A1">What is the definition of an algorithm?</td><td data-t="s" data-v="An algorithm is a well-defined computational procedure that takes some value as input and produces some value as output." id="sjs-B1">An algorithm is a well-defined computational procedure that takes some value as input and produces some value as output.</td></tr><tr><td data-t="s" data-v="What is the primary focus of algorithm analysis, time or space complexity, and why?" id="sjs-A2">What is the primary focus of algorithm analysis, time or space complexity, and why?</td><td data-t="s" data-v="The primary focus is on time complexity because memory is more flexible and easier to expand than the processing speed of hardware." id="sjs-B2">The primary focus is on time complexity because memory is more flexible and easier to expand than the processing speed of hardware.</td></tr><tr><td data-t="s" data-v="Define Time Complexity in the context of algorithm analysis." id="sjs-A3">Define Time Complexity in the context of algorithm analysis.</td><td data-t="s" data-v="Time complexity quantifies the amount of time an algorithm takes to execute as a function of the size of the input (n), focusing on its growth rate." id="sjs-B3">Time complexity quantifies the amount of time an algorithm takes to execute as a function of the size of the input (n), focusing on its growth rate.</td></tr><tr><td data-t="s" data-v="Define Space Complexity in the context of algorithm analysis." id="sjs-A4">Define Space Complexity in the context of algorithm analysis.</td><td data-t="s" data-v="Space complexity measures the total amount of memory an algorithm uses, including fixed and variable parts, as a function of the input size (n)." id="sjs-B4">Space complexity measures the total amount of memory an algorithm uses, including fixed and variable parts, as a function of the input size (n).</td></tr><tr><td data-t="s" data-v="What is worst-case time complexity for an input of size 'n'?" id="sjs-A5">What is worst-case time complexity for an input of size &apos;n&apos;?</td><td data-t="s" data-v="It is the maximum amount of time needed by an algorithm to complete its execution for an input of size n." id="sjs-B5">It is the maximum amount of time needed by an algorithm to complete its execution for an input of size n.</td></tr><tr><td data-t="s" data-v="What is best-case time complexity for an input of size 'n'?" id="sjs-A6">What is best-case time complexity for an input of size &apos;n&apos;?</td><td data-t="s" data-v="It is the minimum amount of time needed by an algorithm to complete its execution for an input of size n." id="sjs-B6">It is the minimum amount of time needed by an algorithm to complete its execution for an input of size n.</td></tr><tr><td data-t="s" data-v="What is average-case time complexity for an input of size 'n'?" id="sjs-A7">What is average-case time complexity for an input of size &apos;n&apos;?</td><td data-t="s" data-v="It is the average amount of time needed by an algorithm, calculated over all possible inputs of size n." id="sjs-B7">It is the average amount of time needed by an algorithm, calculated over all possible inputs of size n.</td></tr><tr><td data-t="s" data-v="What is the purpose of using asymptotic notations in algorithm analysis?" id="sjs-A8">What is the purpose of using asymptotic notations in algorithm analysis?</td><td data-t="s" data-v="They allow the analysis of an algorithm's running time by identifying its behaviour as its input size grows, in a machine-independent manner." id="sjs-B8">They allow the analysis of an algorithm&apos;s running time by identifying its behaviour as its input size grows, in a machine-independent manner.</td></tr><tr><td data-t="s" data-v="Which asymptotic notation is used for analysing the average-case complexity of an algorithm because it encloses the function from above and below?" id="sjs-A9">Which asymptotic notation is used for analysing the average-case complexity of an algorithm because it encloses the function from above and below?</td><td data-t="s" data-v="Theta notation ($\Theta$-notation)." id="sjs-B9">Theta notation ($\Theta$-notation).</td></tr><tr><td data-t="s" data-v="Which asymptotic notation represents the upper bound of the running time and therefore gives the worst-case complexity?" id="sjs-A10">Which asymptotic notation represents the upper bound of the running time and therefore gives the worst-case complexity?</td><td data-t="s" data-v="Big-O notation (O-notation)." id="sjs-B10">Big-O notation (O-notation).</td></tr><tr><td data-t="s" data-v="Which asymptotic notation represents the lower bound of the running time and therefore provides the best-case complexity?" id="sjs-A11">Which asymptotic notation represents the lower bound of the running time and therefore provides the best-case complexity?</td><td data-t="s" data-v="Omega notation ($\Omega$-notation)." id="sjs-B11">Omega notation ($\Omega$-notation).</td></tr><tr><td data-t="s" data-v="Describe the mathematical definition of Theta notation, $f(n) = \Theta(g(n))$." id="sjs-A12">Describe the mathematical definition of Theta notation, $f(n) = \Theta(g(n))$.</td><td data-t="s" data-v="There exist positive constants c1, c2, and n0 such that $0 \le c1 * g(n) \le f(n) \le c2 * g(n)$ for all $n \ge n0$." id="sjs-B12">There exist positive constants c1, c2, and n0 such that $0 \le c1 * g(n) \le f(n) \le c2 * g(n)$ for all $n \ge n0$.</td></tr><tr><td data-t="s" data-v="Describe the mathematical definition of Big-O notation, $f(n) = O(g(n))$." id="sjs-A13">Describe the mathematical definition of Big-O notation, $f(n) = O(g(n))$.</td><td data-t="s" data-v="There exist positive constants c and n0 such that $0 \le f(n) \le c*g(n)$ for all $n \ge n0$." id="sjs-B13">There exist positive constants c and n0 such that $0 \le f(n) \le c*g(n)$ for all $n \ge n0$.</td></tr><tr><td data-t="s" data-v="Describe the mathematical definition of Omega notation, $f(n) = \Omega(g(n))$." id="sjs-A14">Describe the mathematical definition of Omega notation, $f(n) = \Omega(g(n))$.</td><td data-t="s" data-v="There exists a positive constant c and n0 such that $0 \le c*g(n) \le f(n)$ for all $n \ge n0$." id="sjs-B14">There exists a positive constant c and n0 such that $0 \le c*g(n) \le f(n)$ for all $n \ge n0$.</td></tr><tr><td data-t="s" data-v="What are the three main steps involved in the Divide and Conquer approach?" id="sjs-A15">What are the three main steps involved in the Divide and Conquer approach?</td><td data-t="s" data-v="1. Divide the problem into subproblems, 2. Solve each subproblem recursively (Conquer), 3. Combine the solutions." id="sjs-B15">1. Divide the problem into subproblems, 2. Solve each subproblem recursively (Conquer), 3. Combine the solutions.</td></tr><tr><td data-t="s" data-v="What is the core principle of the Greedy algorithm design technique?" id="sjs-A16">What is the core principle of the Greedy algorithm design technique?</td><td data-t="s" data-v="It makes a locally optimal choice at each step with the aim of finding a global optimum." id="sjs-B16">It makes a locally optimal choice at each step with the aim of finding a global optimum.</td></tr><tr><td data-t="s" data-v="How does Dynamic Programming handle subproblems differently from the Divide and Conquer approach?" id="sjs-A17">How does Dynamic Programming handle subproblems differently from the Divide and Conquer approach?</td><td data-t="s" data-v="Dynamic Programming is used for overlapping subproblems, solving each one only once and storing the result for reuse." id="sjs-B17">Dynamic Programming is used for overlapping subproblems, solving each one only once and storing the result for reuse.</td></tr><tr><td data-t="s" data-v="What is the fundamental approach of the Backtracking algorithm?" id="sjs-A18">What is the fundamental approach of the Backtracking algorithm?</td><td data-t="s" data-v="It explores all possibilities by trying choices and undoing them (backtracking) if they lead to a dead end, using a depth-first search approach." id="sjs-B18">It explores all possibilities by trying choices and undoing them (backtracking) if they lead to a dead end, using a depth-first search approach.</td></tr><tr><td data-t="s" data-v="How does the Branch and Bound technique improve upon Backtracking?" id="sjs-A19">How does the Branch and Bound technique improve upon Backtracking?</td><td data-t="s" data-v="It prunes unnecessary branches of the search tree by using bounds on the solution, making it more efficient for optimization problems." id="sjs-B19">It prunes unnecessary branches of the search tree by using bounds on the solution, making it more efficient for optimization problems.</td></tr><tr><td data-t="s" data-v="The _____ algorithm design technique explores all possible solutions exhaustively and is often impractical for large datasets." id="sjs-A20">The _____ algorithm design technique explores all possible solutions exhaustively and is often impractical for large datasets.</td><td data-t="s" data-v="Brute Force" id="sjs-B20">Brute Force</td></tr><tr><td data-t="s" data-v="What is a key disadvantage of the Divide and Conquer approach?" id="sjs-A21">What is a key disadvantage of the Divide and Conquer approach?</td><td data-t="s" data-v="It requires a clear way to divide the problem, and the overhead of recursion can be significant." id="sjs-B21">It requires a clear way to divide the problem, and the overhead of recursion can be significant.</td></tr><tr><td data-t="s" data-v="What is a major limitation of the Greedy approach?" id="sjs-A22">What is a major limitation of the Greedy approach?</td><td data-t="s" data-v="It does not guarantee a globally optimal solution for problems that do not possess the greedy-choice property." id="sjs-B22">It does not guarantee a globally optimal solution for problems that do not possess the greedy-choice property.</td></tr><tr><td data-t="s" data-v="What is the primary disadvantage of using Dynamic Programming?" id="sjs-A23">What is the primary disadvantage of using Dynamic Programming?</td><td data-t="s" data-v="It often has high memory usage due to storing the results of intermediate subproblems." id="sjs-B23">It often has high memory usage due to storing the results of intermediate subproblems.</td></tr><tr><td data-t="s" data-v="What are the time and space complexity characteristics of the Brute Force approach?" id="sjs-A24">What are the time and space complexity characteristics of the Brute Force approach?</td><td data-t="s" data-v="It is computationally expensive with exponential time complexity (e.g., $O(2^n)$) and high space usage." id="sjs-B24">It is computationally expensive with exponential time complexity (e.g., $O(2^n)$) and high space usage.</td></tr><tr><td data-t="s" data-v="Give a real-world example of an algorithm that uses the Divide and Conquer paradigm." id="sjs-A25">Give a real-world example of an algorithm that uses the Divide and Conquer paradigm.</td><td data-t="s" data-v="Merge Sort, Quick Sort, or Binary Search." id="sjs-B25">Merge Sort, Quick Sort, or Binary Search.</td></tr><tr><td data-t="s" data-v="Name an algorithm that exemplifies the Greedy technique." id="sjs-A26">Name an algorithm that exemplifies the Greedy technique.</td><td data-t="s" data-v="Huffman Coding, Kruskal's MST, or Prim's MST." id="sjs-B26">Huffman Coding, Kruskal&apos;s MST, or Prim&apos;s MST.</td></tr><tr><td data-t="s" data-v="What is a classic problem solved using Dynamic Programming?" id="sjs-A27">What is a classic problem solved using Dynamic Programming?</td><td data-t="s" data-v="The Knapsack Problem, Fibonacci Sequence, or Matrix Chain Multiplication." id="sjs-B27">The Knapsack Problem, Fibonacci Sequence, or Matrix Chain Multiplication.</td></tr><tr><td data-t="s" data-v="Provide an example of a problem typically solved with Backtracking." id="sjs-A28">Provide an example of a problem typically solved with Backtracking.</td><td data-t="s" data-v="A Sudoku Solver or the N-Queens Problem." id="sjs-B28">A Sudoku Solver or the N-Queens Problem.</td></tr><tr><td data-t="s" data-v="What is a well-known optimization problem often tackled with the Branch and Bound method?" id="sjs-A29">What is a well-known optimization problem often tackled with the Branch and Bound method?</td><td data-t="s" data-v="The Traveling Salesman Problem or Integer Programming." id="sjs-B29">The Traveling Salesman Problem or Integer Programming.</td></tr><tr><td data-t="s" data-v="What is an operation count in the context of algorithm analysis?" id="sjs-A30">What is an operation count in the context of algorithm analysis?</td><td data-t="s" data-v="It is a method to estimate time complexity by counting the number of times a specific, dominant operation is performed." id="sjs-B30">It is a method to estimate time complexity by counting the number of times a specific, dominant operation is performed.</td></tr><tr><td data-t="s" data-v="What is a line count or step count in algorithm analysis?" id="sjs-A31">What is a line count or step count in algorithm analysis?</td><td data-t="s" data-v="It is a method to estimate time complexity by counting the number of executed statements or steps in an algorithm." id="sjs-B31">It is a method to estimate time complexity by counting the number of executed statements or steps in an algorithm.</td></tr><tr><td data-t="s" data-v="In step counting, what is the typical execution count for a 'for' loop statement like 'for (int i = 0; i < n; i++)'?" id="sjs-A32">In step counting, what is the typical execution count for a &apos;for&apos; loop statement like &apos;for (int i = 0; i &lt; n; i++)&apos;?</td><td data-t="s" data-v="The statement is executed 'n+1' times." id="sjs-B32">The statement is executed &apos;n+1&apos; times.</td></tr><tr><td data-t="s" data-v="What defines a Randomized Algorithm?" id="sjs-A33">What defines a Randomized Algorithm?</td><td data-t="s" data-v="It is an algorithm that uses a source of random bits to influence its computation and decision-making." id="sjs-B33">It is an algorithm that uses a source of random bits to influence its computation and decision-making.</td></tr><tr><td data-t="s" data-v="What is a recurrence relation?" id="sjs-A34">What is a recurrence relation?</td><td data-t="s" data-v="A recurrence is an equation or inequality that describes a function in terms of its value on smaller inputs, often used for recursive algorithms." id="sjs-B34">A recurrence is an equation or inequality that describes a function in terms of its value on smaller inputs, often used for recursive algorithms.</td></tr><tr><td data-t="s" data-v="What are the three methods mentioned for solving recurrence relations?" id="sjs-A35">What are the three methods mentioned for solving recurrence relations?</td><td data-t="s" data-v="The substitution method, the recursion-tree method, and the master method." id="sjs-B35">The substitution method, the recursion-tree method, and the master method.</td></tr><tr><td data-t="s" data-v="What are the two steps of the substitution method for solving recurrences?" id="sjs-A36">What are the two steps of the substitution method for solving recurrences?</td><td data-t="s" data-v="1. Guess the form of the solution. 2. Use mathematical induction to prove the guess is correct." id="sjs-B36">1. Guess the form of the solution. 2. Use mathematical induction to prove the guess is correct.</td></tr><tr><td data-t="s" data-v="What is the purpose of the recursion-tree method?" id="sjs-A37">What is the purpose of the recursion-tree method?</td><td data-t="s" data-v="It converts a recurrence into a tree to visualise costs at each level, which helps in generating a good guess for the solution's bound." id="sjs-B37">It converts a recurrence into a tree to visualise costs at each level, which helps in generating a good guess for the solution&apos;s bound.</td></tr><tr><td data-t="s" data-v="The Master Method provides a 'cookbook' solution for recurrences of what specific form?" id="sjs-A38">The Master Method provides a &apos;cookbook&apos; solution for recurrences of what specific form?</td><td data-t="s" data-v="Recurrences of the form $T(n) = aT(n/b) + f(n)$, where $a \ge 1$ and $b > 1$." id="sjs-B38">Recurrences of the form $T(n) = aT(n/b) + f(n)$, where $a \ge 1$ and $b &gt; 1$.</td></tr><tr><td data-t="s" data-v="In the Master Theorem, what two values are compared to determine which case applies?" id="sjs-A39">In the Master Theorem, what two values are compared to determine which case applies?</td><td data-t="s" data-v="The function $f(n)$ is compared to the value $n^{\log_b a}$." id="sjs-B39">The function $f(n)$ is compared to the value $n^{\log_b a}$.</td></tr><tr><td data-t="s" data-v="According to the Master Theorem, if $f(n) = O(n^{\log_b a - \epsilon})$ for some constant $\epsilon > 0$, what is the solution for T(n)?" id="sjs-A40">According to the Master Theorem, if $f(n) = O(n^{\log_b a - \epsilon})$ for some constant $\epsilon &gt; 0$, what is the solution for T(n)?</td><td data-t="s" data-v="The solution is $T(n) = \Theta(n^{\log_b a})$." id="sjs-B40">The solution is $T(n) = \Theta(n^{\log_b a})$.</td></tr><tr><td data-t="s" data-v="According to the Master Theorem, if $f(n) = \Theta(n^{\log_b a})$, what is the solution for T(n)?" id="sjs-A41">According to the Master Theorem, if $f(n) = \Theta(n^{\log_b a})$, what is the solution for T(n)?</td><td data-t="s" data-v="The solution is $T(n) = \Theta(n^{\log_b a} \log n)$." id="sjs-B41">The solution is $T(n) = \Theta(n^{\log_b a} \log n)$.</td></tr><tr><td data-t="s" data-v="According to the Master Theorem, if $f(n) = \Omega(n^{\log_b a + \epsilon})$ and a regularity condition holds, what is the solution for T(n)?" id="sjs-A42">According to the Master Theorem, if $f(n) = \Omega(n^{\log_b a + \epsilon})$ and a regularity condition holds, what is the solution for T(n)?</td><td data-t="s" data-v="The solution is $T(n) = \Theta(f(n))$." id="sjs-B42">The solution is $T(n) = \Theta(f(n))$.</td></tr><tr><td data-t="s" data-v="Using the Master Theorem, solve the recurrence $T(n) = 9T(n/3) + n$." id="sjs-A43">Using the Master Theorem, solve the recurrence $T(n) = 9T(n/3) + n$.</td><td data-t="s" data-v="$T(n) = \Theta(n^2)$ (Case 1 applies as $n^{\log_3 9} = n^2$ and $f(n)=n = O(n^{2-1})$)." id="sjs-B43">$T(n) = \Theta(n^2)$ (Case 1 applies as $n^{\log_3 9} = n^2$ and $f(n)=n = O(n^{2-1})$).</td></tr><tr><td data-t="s" data-v="What is the Transitive Property of asymptotic notations?" id="sjs-A44">What is the Transitive Property of asymptotic notations?</td><td data-t="s" data-v="If $f(n)$ is O(g(n)) and g(n) is O(h(n)), then $f(n)$ is O(h(n)). This also applies to $\Omega$ and $\Theta$." id="sjs-B44">If $f(n)$ is O(g(n)) and g(n) is O(h(n)), then $f(n)$ is O(h(n)). This also applies to $\Omega$ and $\Theta$.</td></tr><tr><td data-t="s" data-v="What is the Reflexive Property of asymptotic notations?" id="sjs-A45">What is the Reflexive Property of asymptotic notations?</td><td data-t="s" data-v="For any given function f(n), f(n) is O(f(n)), $\Omega(f(n))$, and $\Theta(f(n))$." id="sjs-B45">For any given function f(n), f(n) is O(f(n)), $\Omega(f(n))$, and $\Theta(f(n))$.</td></tr><tr><td data-t="s" data-v="Which asymptotic notation has the Symmetric Property, stating that if $f(n)$ is $\Theta(g(n))$, then g(n) is $\Theta(f(n))$?" id="sjs-A46">Which asymptotic notation has the Symmetric Property, stating that if $f(n)$ is $\Theta(g(n))$, then g(n) is $\Theta(f(n))$?</td><td data-t="s" data-v="Only Theta ($\Theta$) notation." id="sjs-B46">Only Theta ($\Theta$) notation.</td></tr><tr><td data-t="s" data-v="What does the Transpose Symmetric Property of asymptotic notations state?" id="sjs-A47">What does the Transpose Symmetric Property of asymptotic notations state?</td><td data-t="s" data-v="If f(n) is O(g(n)), then g(n) is $\Omega(f(n))$." id="sjs-B47">If f(n) is O(g(n)), then g(n) is $\Omega(f(n))$.</td></tr><tr><td data-t="s" data-v="If $f(n) = O(g(n))$ and $f(n) = \Omega(g(n))$, what can be concluded about the relationship between f(n) and g(n)?" id="sjs-A48">If $f(n) = O(g(n))$ and $f(n) = \Omega(g(n))$, what can be concluded about the relationship between f(n) and g(n)?</td><td data-t="s" data-v="It can be concluded that $f(n) = \Theta(g(n))$." id="sjs-B48">It can be concluded that $f(n) = \Theta(g(n))$.</td></tr><tr><td data-t="s" data-v="What kind of time complexity does an algorithm have if its execution time is constant regardless of the input size?" id="sjs-A49">What kind of time complexity does an algorithm have if its execution time is constant regardless of the input size?</td><td data-t="s" data-v="Constant Time, denoted as O(1)." id="sjs-B49">Constant Time, denoted as O(1).</td></tr><tr><td data-t="s" data-v="What kind of time complexity does an algorithm like binary search have, where execution time grows logarithmically with input size?" id="sjs-A50">What kind of time complexity does an algorithm like binary search have, where execution time grows logarithmically with input size?</td><td data-t="s" data-v="Logarithmic Time, denoted as O(log n)." id="sjs-B50">Logarithmic Time, denoted as O(log n).</td></tr><tr><td data-t="s" data-v="What kind of time complexity is associated with nested loops, such as in Bubble Sort?" id="sjs-A51">What kind of time complexity is associated with nested loops, such as in Bubble Sort?</td><td data-t="s" data-v="Quadratic Time, denoted as $O(n^2)$." id="sjs-B51">Quadratic Time, denoted as $O(n^2)$.</td></tr><tr><td data-t="s" data-v="The time complexity where execution time doubles with each additional input element is known as _____." id="sjs-A52">The time complexity where execution time doubles with each additional input element is known as _____.</td><td data-t="s" data-v="Exponential Time, denoted as $O(2^n)$." id="sjs-B52">Exponential Time, denoted as $O(2^n)$.</td></tr><tr><td data-t="s" data-v="What is Linear Recursion?" id="sjs-A53">What is Linear Recursion?</td><td data-t="s" data-v="A recursive function that makes only a single call to itself each time it runs, typically resulting in linear time complexity." id="sjs-B53">A recursive function that makes only a single call to itself each time it runs, typically resulting in linear time complexity.</td></tr><tr><td data-t="s" data-v="What is Tree Recursion?" id="sjs-A54">What is Tree Recursion?</td><td data-t="s" data-v="A recursive function that makes more than one call to itself in its recursive case, often leading to exponential time complexity." id="sjs-B54">A recursive function that makes more than one call to itself in its recursive case, often leading to exponential time complexity.</td></tr><tr><td data-t="s" data-v="The Fibonacci function is a classic example of which type of recursion?" id="sjs-A55">The Fibonacci function is a classic example of which type of recursion?</td><td data-t="s" data-v="Tree Recursion." id="sjs-B55">Tree Recursion.</td></tr><tr><td data-t="s" data-v="What is the recurrence relation for a typical linear recursive function that reduces the problem size by one?" id="sjs-A56">What is the recurrence relation for a typical linear recursive function that reduces the problem size by one?</td><td data-t="s" data-v="$T(n) = T(n-1) + k$, where k is a constant." id="sjs-B56">$T(n) = T(n-1) + k$, where k is a constant.</td></tr><tr><td data-t="s" data-v="What is the recurrence relation for the tree recursive Fibonacci function?" id="sjs-A57">What is the recurrence relation for the tree recursive Fibonacci function?</td><td data-t="s" data-v="$T(n) = T(n-1) + T(n-2) + k$, where k is a constant." id="sjs-B57">$T(n) = T(n-1) + T(n-2) + k$, where k is a constant.</td></tr><tr><td data-t="s" data-v="In the context of algorithm analysis, what is the 'fixed part' of space complexity?" id="sjs-A58">In the context of algorithm analysis, what is the &apos;fixed part&apos; of space complexity?</td><td data-t="s" data-v="It is the memory used for variables, constants, and program instructions, which does not depend on the input size." id="sjs-B58">It is the memory used for variables, constants, and program instructions, which does not depend on the input size.</td></tr><tr><td data-t="s" data-v="In the context of algorithm analysis, what is the 'variable part' of space complexity?" id="sjs-A59">In the context of algorithm analysis, what is the &apos;variable part&apos; of space complexity?</td><td data-t="s" data-v="It is the memory required during execution that depends on the input size n, including auxiliary and input space." id="sjs-B59">It is the memory required during execution that depends on the input size n, including auxiliary and input space.</td></tr><tr><td data-t="s" data-v="The Greedy approach works best for problems that have the greedy choice property and _____." id="sjs-A60">The Greedy approach works best for problems that have the greedy choice property and _____.</td><td data-t="s" data-v="optimal substructure" id="sjs-B60">optimal substructure</td></tr><tr><td data-t="s" data-v="What is the approach type of the Dynamic Programming paradigm?" id="sjs-A61">What is the approach type of the Dynamic Programming paradigm?</td><td data-t="s" data-v="It is a bottom-up or memoization-based approach." id="sjs-B61">It is a bottom-up or memoization-based approach.</td></tr><tr><td data-t="s" data-v="What is the key technique used in Dynamic Programming to improve efficiency?" id="sjs-A62">What is the key technique used in Dynamic Programming to improve efficiency?</td><td data-t="s" data-v="Memoization or tabulation to store and reuse intermediate results of overlapping subproblems." id="sjs-B62">Memoization or tabulation to store and reuse intermediate results of overlapping subproblems.</td></tr><tr><td data-t="s" data-v="Which design paradigm is considered a 'last resort' for small datasets or when no better method is known?" id="sjs-A63">Which design paradigm is considered a &apos;last resort&apos; for small datasets or when no better method is known?</td><td data-t="s" data-v="Brute Force." id="sjs-B63">Brute Force.</td></tr><tr><td data-t="s" data-v="The time complexity of Merge Sort, a Divide and Conquer algorithm, is typically _____." id="sjs-A64">The time complexity of Merge Sort, a Divide and Conquer algorithm, is typically _____.</td><td data-t="s" data-v="O(n log n)." id="sjs-B64">O(n log n).</td></tr><tr><td data-t="s" data-v="What is a major advantage of the Greedy approach for suitable problems?" id="sjs-A65">What is a major advantage of the Greedy approach for suitable problems?</td><td data-t="s" data-v="It is fast and simple to implement." id="sjs-B65">It is fast and simple to implement.</td></tr><tr><td data-t="s" data-v="What advantage does Branch and Bound offer over a simple Backtracking search?" id="sjs-A66">What advantage does Branch and Bound offer over a simple Backtracking search?</td><td data-t="s" data-v="It reduces unnecessary exploration of the solution space by pruning branches using calculated bounds." id="sjs-B66">It reduces unnecessary exploration of the solution space by pruning branches using calculated bounds.</td></tr><tr><td data-t="s" data-v="What is the worst-case time complexity of a Linear Search algorithm on an array of size n?" id="sjs-A67">What is the worst-case time complexity of a Linear Search algorithm on an array of size n?</td><td data-t="s" data-v="$O(n)$." id="sjs-B67">$O(n)$.</td></tr><tr><td data-t="s" data-v="What is the best-case time complexity of a Linear Search algorithm on an array of size n?" id="sjs-A68">What is the best-case time complexity of a Linear Search algorithm on an array of size n?</td><td data-t="s" data-v="$O(1)$." id="sjs-B68">$O(1)$.</td></tr><tr><td data-t="s" data-v="The Master Method is used for finding the time complexity of a _____ function." id="sjs-A69">The Master Method is used for finding the time complexity of a _____ function.</td><td data-t="s" data-v="recursive" id="sjs-B69">recursive</td></tr><tr><td data-t="s" data-v="In the Master Theorem's general form $T(n) = aT(n/b) + f(n)$, what does 'a' represent?" id="sjs-A70">In the Master Theorem&apos;s general form $T(n) = aT(n/b) + f(n)$, what does &apos;a&apos; represent?</td><td data-t="s" data-v="'a' represents the number of subproblems the main problem is divided into." id="sjs-B70">&apos;a&apos; represents the number of subproblems the main problem is divided into.</td></tr><tr><td data-t="s" data-v="In the Master Theorem's general form $T(n) = aT(n/b) + f(n)$, what does 'n/b' represent?" id="sjs-A71">In the Master Theorem&apos;s general form $T(n) = aT(n/b) + f(n)$, what does &apos;n/b&apos; represent?</td><td data-t="s" data-v="'n/b' represents the size of each subproblem." id="sjs-B71">&apos;n/b&apos; represents the size of each subproblem.</td></tr><tr><td data-t="s" data-v="How do little-o and little-omega notations differ from Big-O and Big-Omega?" id="sjs-A72">How do little-o and little-omega notations differ from Big-O and Big-Omega?</td><td data-t="s" data-v="Little-o provides a strict upper bound and little-omega provides a strict lower bound, meaning the equality condition is removed." id="sjs-B72">Little-o provides a strict upper bound and little-omega provides a strict lower bound, meaning the equality condition is removed.</td></tr></table></body></html></body></html>