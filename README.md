# AI Document Analysis Engine
This repository contains the backend for an AI-powered, RAG-based (Retrieval Augmented Generation) Document Analysis system.  
The system supports uploading documents (PDF/TXT), extracting text, generating AI summaries and embeddings, storing vectors in Pinecone, and performing semantic search over uploaded content.

This README is the **contract** between backend and frontend.

## ğŸ“¦ Project Structure

root/
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ config/          # Database & external service configuration
â”‚   â”œâ”€â”€ controllers/     # Request handling logic
â”‚   â”œâ”€â”€ models/          # Mongoose schemas
â”‚   â”œâ”€â”€ routes/          # API routes
â”‚   â”œâ”€â”€ services/        # AI + Vector DB logic
â”‚   â”œâ”€â”€ uploads/         # Temporary file storage
â”‚   â”œâ”€â”€ .env             # Environment variables (NOT committed)
â”‚   â”œâ”€â”€ server.js        # Application entry point
â”‚   â””â”€â”€ package.json

## ğŸš€ Quick Start

### 1. Prerequisites

You must have the following installed or available:
- Node.js **v18+**
- MongoDB (Atlas or local)
- OpenAI API Key (for summaries + embeddings)
- Pinecone API Key (for vector search)

### 2. Installation

Navigate to the backend folder and install dependencies:

```bash
cd server
npm install
```

### 3. Environment Setup

Create a `.env` file inside the `server/` directory.

```env
PORT=5000
MONGO_URI=your_mongodb_connection_string
OPENAI_API_KEY=your_openai_api_key
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_INDEX_NAME=workspace-index
```

âš ï¸ **Never commit `.env` to Git.**

### 4. Run the Server

```bash
# Development mode (auto-restart on file changes)
npm run dev
```

The server will start at:
http://localhost:5000

## ğŸ“¡ API Documentation

### 1ï¸âƒ£ Upload Document

Uploads a document, extracts text, generates AI summary and embeddings, stores vectors in Pinecone, and metadata in MongoDB.

**Endpoint**
```
POST /api/upload
```

**Request**
- Type: `multipart/form-data`
- Field:
  - `file`: PDF or TXT file

**Response**
```json
{
  "message": "File processed",
  "file": {
    "fileName": "example.pdf",
    "fileType": "pdf",
    "summary": "Short AI-generated summary..."
  }
}
```

**Notes**
- Only text-based PDFs are supported
- Scanned/image-only or encrypted PDFs will fail gracefully

### 2ï¸âƒ£ Semantic Search

Searches documents using meaning-based (vector) similarity.

**Endpoint**
```
POST /api/search
```

**Headers**
```
Content-Type: application/json
```

**Request Body**
```json
{
  "query": "What is the budget for Q1?"
}
```

**Response**
```json
[
  {
    "score": 0.89,
    "fileName": "Project_Alpha.pdf",
    "summary": "Budget allocation details for Q1..."
  }
]
```

## ğŸ§  How the Backend Works (High-Level Flow)

```
Upload File
   â†“
Text Extraction (PDF/TXT)
   â†“
AI Summary + Embeddings (OpenAI)
   â†“
Vector Storage (Pinecone)
   â†“
Metadata Storage (MongoDB)
   â†“
Semantic Search via Query Embeddings
```

## ğŸ›  Available Scripts

From the `server/` directory:

- **Development Server**
  bash
  npm run dev

- **PDF Parser Test**
  bash
  node test-pdf.js
  
  Used to verify that the PDF parsing library is functioning correctly.

- **Database Seed (Optional)**
  bash
  node scripts/seed.js
  
  Clears the database and inserts dummy records for UI testing.

## ğŸ”’ Security & Git Hygiene

Ensure your root `.gitignore` contains:

```text
node_modules
.env
.DS_Store
```

Secrets **must never** be pushed to GitHub.

## âœ… Current Capabilities

- File upload (PDF/TXT)
- Robust PDF parsing with failure handling
- AI-generated summaries
- Vector embeddings
- Semantic search using Pinecone
- MongoDB persistence
- Clean, modular backend architecture

## ğŸš§ Known Limitations

- Scanned/image PDFs are not supported (OCR not implemented)
- No authentication layer yet
- No rate limiting (dev-focused)

## ğŸ“Œ Project Status

**Phase 4 Completed**

The backend is:
- Functional
- Documented
- Stable
- Ready for frontend integration

This README is the single source of truth.  
If someone asks a question already answered here, thatâ€™s on them.
